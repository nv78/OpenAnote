{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Go5AH5PI-HFL",
        "ROY6Crjb-XQl",
        "YZ9tolra-eWQ",
        "gmN-8zM3-opk",
        "qgUHCwjD-t27",
        "40hpF5FL_Qdc",
        "9zgTydEE_ZrD",
        "NnPS142F_tZx",
        "ryW6eHt__7ji",
        "hL61BKS0Al55"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n"
      ],
      "metadata": {
        "id": "Go5AH5PI-HFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ROY6Crjb-XQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fT1egnP_2a8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a03b71-0712-407e-bade-62f6adb42c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.162)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Kaggle dataset"
      ],
      "metadata": {
        "id": "YZ9tolra-eWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"ollypowell/fair1m-satellite-imagery-for-object-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvRmqdv9ZbPO",
        "outputId": "a737bcc2-02db-4b84-e241-51aa82952066",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/fair1m-satellite-imagery-for-object-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organize dataset"
      ],
      "metadata": {
        "id": "gmN-8zM3-opk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_parquet(os.path.join(path, \"Dataset\", \"labels.parquet\"))\n",
        "\n",
        "base_dir = \"fair1m\"\n",
        "base_label_dir = os.path.join(base_dir, \"labels\")\n",
        "base_image_dir = os.path.join(base_dir, \"images\")\n",
        "\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "os.makedirs(f\"{base_label_dir}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{base_label_dir}/val\", exist_ok=True)\n",
        "os.makedirs(f\"{base_image_dir}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{base_image_dir}/val\", exist_ok=True)\n",
        "\n",
        "class_names = sorted(labels_df[\"Category\"].unique())\n",
        "class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "with open(os.path.join(base_dir, \"classes.txt\"), \"w\") as f:\n",
        "    for name in class_names:\n",
        "        f.write(name + \"\\n\")\n",
        "\n",
        "for _, row in labels_df.iterrows():\n",
        "    filepath = row[\"FilePath\"].replace(\"/home/olly/Desktop/Gaofen_Challenge/Dataset/Images/\", os.path.join(path, \"Dataset\", \"Images\") + \"/\"\n",
        ")\n",
        "\n",
        "    category = row[\"Category\"]\n",
        "    split = row[\"Split\"].lower()\n",
        "\n",
        "    x_min, y_min = row[\"x_min\"], row[\"y_min\"]\n",
        "    x_max, y_max = row[\"x_max\"], row[\"y_max\"]\n",
        "    img_w, img_h = row[\"ImageWidth\"], row[\"ImageHeight\"]\n",
        "\n",
        "    filename = os.path.basename(filepath)\n",
        "    name_no_ext = os.path.splitext(filename)[0]\n",
        "\n",
        "    x_center = ((x_min + x_max) / 2) / img_w\n",
        "    y_center = ((y_min + y_max) / 2) / img_h\n",
        "    width = (x_max - x_min) / img_w\n",
        "    height = (y_max - y_min) / img_h\n",
        "\n",
        "    label_path = os.path.join(base_label_dir, split, name_no_ext + \".txt\")\n",
        "\n",
        "    class_id = class_to_id[category]\n",
        "    with open(label_path, \"a\") as f:\n",
        "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "    dest_image_path = os.path.join(base_image_dir, split, filename)\n",
        "    if not os.path.exists(dest_image_path):\n",
        "        if os.path.exists(filepath):\n",
        "            os.system(f'cp \"{filepath}\" \"{dest_image_path}\"')\n",
        "        else:\n",
        "            print(f\"Missing image: {filepath}\")\n"
      ],
      "metadata": {
        "id": "hy4nlFmBxynR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LONG Training\n",
        "\n",
        "Training on full dataset, for 50 epochs"
      ],
      "metadata": {
        "id": "i-3TNcwO-nwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create yaml file"
      ],
      "metadata": {
        "id": "qgUHCwjD-t27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = \"/content/fair1m\"\n",
        "train_path = os.path.join(dataset_root, \"images/train\")\n",
        "val_path = os.path.join(dataset_root, \"images/val\")\n",
        "\n",
        "if not os.path.exists(train_path):\n",
        "    raise FileNotFoundError(f\"Train path not found: {train_path}\")\n",
        "if not os.path.exists(val_path):\n",
        "    raise FileNotFoundError(f\"Val path not found: {val_path}\")\n",
        "\n",
        "with open(os.path.join(dataset_root, \"classes.txt\"), \"r\") as f:\n",
        "    class_names = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "data_yaml_path = os.path.join(dataset_root, \"data.yaml\")\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    f.write(f\"path: {dataset_root}\\n\")\n",
        "    f.write(\"train: images/train\\n\")\n",
        "    f.write(\"val: images/val\\n\")\n",
        "    f.write(f\"nc: {len(class_names)}\\n\")\n",
        "    f.write(\"names:\\n\")\n",
        "    for name in class_names:\n",
        "        f.write(f\"  - {name}\\n\")\n",
        "\n",
        "print(f\"Saved data.yaml to {data_yaml_path}\")\n"
      ],
      "metadata": {
        "id": "p801tsDA6BGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "6ByObUY5GUXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = \"/content/fair1m\"\n",
        "val_path = os.path.join(dataset_root, \"images/val\")\n",
        "class_file = os.path.join(dataset_root, \"classes.txt\")\n",
        "\n",
        "with open(class_file, \"r\") as f:\n",
        "    class_names = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "results = model.predict(source=val_path, stream=True, conf=0.25)\n",
        "\n",
        "predictions = []\n",
        "img_id = 0\n",
        "for r in results:\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    if r.boxes is not None:\n",
        "        for box in r.boxes:\n",
        "            xyxy = box.xyxy[0].cpu().numpy().astype(int).tolist()\n",
        "            cls_id = int(box.cls[0])\n",
        "            label = class_names[cls_id] if cls_id < len(class_names) else f\"class_{cls_id}\"\n",
        "            boxes.append(xyxy)\n",
        "            labels.append(label)\n",
        "    predictions.append({\n",
        "        \"id\": img_id,\n",
        "        \"original_id\": r.path,\n",
        "        \"label\": labels,\n",
        "        \"boxes\": boxes\n",
        "    })\n",
        "    img_id += 1\n",
        "\n",
        "with open(\"predictions.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=2)\n"
      ],
      "metadata": {
        "id": "2i0tBIQivHY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ground Truths JSON file"
      ],
      "metadata": {
        "id": "qoI3mG41GjD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ground_truths.json\", \"w\") as f:\n",
        "    json.dump(ground_truths, f, indent=2)\n",
        "print(\"Saved ground_truths.json\")"
      ],
      "metadata": {
        "id": "XPXnAgKoGilH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions JSON files"
      ],
      "metadata": {
        "id": "6hqYeBSMGScj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"predictions.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=2)\n",
        "print(\"Saved predictions.json\")\n",
        "\n",
        "ground_truths = []\n",
        "img_id = 0\n",
        "for filename in sorted(os.listdir(val_path)):\n",
        "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "        continue\n",
        "    image_path = os.path.join(val_path, filename)\n",
        "    label_path = os.path.join(label_val_path, os.path.splitext(filename)[0] + \".txt\")\n",
        "    if not os.path.exists(label_path):\n",
        "        continue\n",
        "    img = cv2.imread(image_path)\n",
        "    h, w = img.shape[:2]\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    with open(label_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            cls_id = int(parts[0])\n",
        "            cx, cy, bw, bh = map(float, parts[1:])\n",
        "            x1 = int((cx - bw / 2) * w)\n",
        "            y1 = int((cy - bh / 2) * h)\n",
        "            x2 = int((cx + bw / 2) * w)\n",
        "            y2 = int((cy + bh / 2) * h)\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "            labels.append(class_names[cls_id] if cls_id < len(class_names) else f\"class_{cls_id}\")\n",
        "    if boxes:\n",
        "        ground_truths.append({\n",
        "            \"id\": img_id,\n",
        "            \"original_id\": image_path,\n",
        "            \"label\": labels,\n",
        "            \"boxes\": boxes\n",
        "        })\n",
        "        img_id += 1"
      ],
      "metadata": {
        "id": "QPfVxqy1GEgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHORT Training\n",
        "\n",
        "Training on 100 randomly selected images, for only 3 epochs"
      ],
      "metadata": {
        "id": "40hpF5FL_Qdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create filtered train, val, and yaml file"
      ],
      "metadata": {
        "id": "9zgTydEE_ZrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = \"/content/fair1m\"\n",
        "train_dir = os.path.join(dataset_root, \"images/train\")\n",
        "val_dir = os.path.join(dataset_root, \"images/val\")\n",
        "\n",
        "def get_first_n_images(dir_path, n=100):\n",
        "    files = sorted([os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
        "    return files[:n]\n",
        "\n",
        "train_images = get_first_n_images(train_dir, 100)\n",
        "val_images = get_first_n_images(val_dir, 100)\n",
        "\n",
        "train_txt = os.path.join(dataset_root, \"train_subset.txt\")\n",
        "val_txt = os.path.join(dataset_root, \"val_subset.txt\")\n",
        "\n",
        "with open(train_txt, \"w\") as f:\n",
        "    f.write(\"\\n\".join(train_images) + \"\\n\")\n",
        "\n",
        "with open(val_txt, \"w\") as f:\n",
        "    f.write(\"\\n\".join(val_images) + \"\\n\")\n",
        "\n",
        "with open(os.path.join(dataset_root, \"data_filtered.yaml\"), \"w\") as f:\n",
        "    f.write(f\"train: {train_txt}\\n\")\n",
        "    f.write(f\"val: {val_txt}\\n\")\n",
        "    f.write(f\"nc: {len(class_names)}\\n\")\n",
        "    f.write(\"names:\\n\")\n",
        "    for name in class_names:\n",
        "        f.write(f\"  - {name}\\n\")\n",
        "\n",
        "print(\"Created train_subset.txt, val_subset.txt and data_filtered.yaml\")\n"
      ],
      "metadata": {
        "id": "Yc4-r4enwaM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "NnPS142F_tZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8s.pt\")\n",
        "model.train(data=\"/content/fair1m/data_filtered.yaml\", epochs=3, imgsz=640)"
      ],
      "metadata": {
        "id": "16cKPvQWvmOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ground Truths JSON file"
      ],
      "metadata": {
        "id": "ryW6eHt__7ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/fair1m/images/val\"\n",
        "label_dir = \"/content/fair1m/labels/val\"\n",
        "classes_path = \"/content/fair1m/classes.txt\"\n",
        "\n",
        "with open(classes_path) as f:\n",
        "    class_names = [line.strip() for line in f]\n",
        "\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(image_dir)\n",
        "    if f.lower().endswith((\".jpg\", \".png\"))\n",
        "])[:100]\n",
        "\n",
        "ground_truths = []\n",
        "\n",
        "for idx, image_file in enumerate(image_files):\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    label_file = os.path.join(label_dir, os.path.splitext(image_file)[0] + \".txt\")\n",
        "\n",
        "    if not os.path.exists(label_file):\n",
        "        continue\n",
        "\n",
        "    with Image.open(image_path) as img:\n",
        "        width, height = img.size\n",
        "\n",
        "    labels = []\n",
        "    boxes = []\n",
        "\n",
        "    with open(label_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "\n",
        "            class_id, x_center, y_center, w, h = map(float, parts)\n",
        "            class_id = int(class_id)\n",
        "            if not (0 <= class_id < len(class_names)):\n",
        "                continue\n",
        "\n",
        "            xc, yc, bw, bh = x_center * width, y_center * height, w * width, h * height\n",
        "            xmin = int(xc - bw / 2)\n",
        "            ymin = int(yc - bh / 2)\n",
        "            xmax = int(xc + bw / 2)\n",
        "            ymax = int(yc + bh / 2)\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(class_names[class_id])\n",
        "\n",
        "    if boxes:\n",
        "        ground_truths.append({\n",
        "            \"id\": idx,\n",
        "            \"original_id\": image_path,\n",
        "            \"label\": labels,\n",
        "            \"boxes\": boxes\n",
        "        })\n",
        "\n",
        "with open(\"ground_truths.json\", \"w\") as f:\n",
        "    json.dump(ground_truths, f, indent=2)\n"
      ],
      "metadata": {
        "id": "aibhkBuV81Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions JSON file"
      ],
      "metadata": {
        "id": "hL61BKS0Al55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "with open(\"/content/fair1m/classes.txt\") as f:\n",
        "    class_names = [line.strip() for line in f]\n",
        "\n",
        "val_dir = \"/content/fair1m/images/val\"\n",
        "image_paths = sorted([\n",
        "    os.path.join(val_dir, f)\n",
        "    for f in os.listdir(val_dir)\n",
        "    if f.lower().endswith((\".jpg\", \".png\"))\n",
        "])[:100]\n",
        "\n",
        "predictions = []\n",
        "for idx, img_path in enumerate(image_paths):\n",
        "    result = model(img_path)[0]\n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        xyxy = box.xyxy[0].cpu().numpy().astype(int).tolist()\n",
        "        cls_id = int(box.cls[0])\n",
        "        if 0 <= cls_id < len(class_names):\n",
        "            boxes.append(xyxy)\n",
        "            labels.append(class_names[cls_id])\n",
        "\n",
        "    predictions.append({\n",
        "        \"id\": idx,\n",
        "        \"original_id\": img_path,\n",
        "        \"label\": labels,\n",
        "        \"boxes\": boxes\n",
        "    })\n",
        "\n",
        "with open(\"predictions.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkLjRAXI1icY",
        "outputId": "906e9f0b-81c0-42c4-9d6e-c3d058b8d028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/fair1m/images/val/v_0.jpg: 640x640 (no detections), 565.3ms\n",
            "Speed: 6.9ms preprocess, 565.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1.jpg: 640x640 (no detections), 680.4ms\n",
            "Speed: 4.6ms preprocess, 680.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_10.jpg: 640x480 (no detections), 687.1ms\n",
            "Speed: 5.8ms preprocess, 687.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_100.jpg: 480x640 (no detections), 664.3ms\n",
            "Speed: 5.0ms preprocess, 664.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1000.jpg: 640x640 1 Baseball Field, 842.9ms\n",
            "Speed: 7.1ms preprocess, 842.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1001.jpg: 480x640 (no detections), 424.7ms\n",
            "Speed: 3.6ms preprocess, 424.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1002.jpg: 640x480 (no detections), 411.5ms\n",
            "Speed: 3.8ms preprocess, 411.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1003.jpg: 640x640 (no detections), 552.3ms\n",
            "Speed: 4.5ms preprocess, 552.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1004.jpg: 640x480 (no detections), 410.7ms\n",
            "Speed: 3.3ms preprocess, 410.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1005.jpg: 640x480 (no detections), 409.9ms\n",
            "Speed: 3.3ms preprocess, 409.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1006.jpg: 640x640 (no detections), 551.7ms\n",
            "Speed: 4.7ms preprocess, 551.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1007.jpg: 640x480 4 Baseball Fields, 1 Boeing777, 419.3ms\n",
            "Speed: 3.4ms preprocess, 419.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1008.jpg: 640x480 (no detections), 423.3ms\n",
            "Speed: 4.5ms preprocess, 423.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1009.jpg: 640x640 (no detections), 537.1ms\n",
            "Speed: 4.6ms preprocess, 537.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_101.jpg: 640x640 (no detections), 552.0ms\n",
            "Speed: 5.2ms preprocess, 552.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1010.jpg: 640x480 (no detections), 416.5ms\n",
            "Speed: 3.5ms preprocess, 416.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1011.jpg: 480x640 (no detections), 422.4ms\n",
            "Speed: 3.4ms preprocess, 422.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1012.jpg: 640x480 (no detections), 419.0ms\n",
            "Speed: 3.6ms preprocess, 419.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1013.jpg: 480x640 (no detections), 422.4ms\n",
            "Speed: 3.7ms preprocess, 422.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1014.jpg: 640x480 (no detections), 414.0ms\n",
            "Speed: 3.4ms preprocess, 414.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1015.jpg: 480x640 1 Baseball Field, 412.9ms\n",
            "Speed: 4.0ms preprocess, 412.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1016.jpg: 640x640 2 Baseball Fields, 1 Boeing777, 558.2ms\n",
            "Speed: 5.2ms preprocess, 558.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1017.jpg: 640x640 (no detections), 552.3ms\n",
            "Speed: 4.6ms preprocess, 552.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1018.jpg: 640x640 (no detections), 541.6ms\n",
            "Speed: 4.6ms preprocess, 541.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1019.jpg: 640x640 (no detections), 553.3ms\n",
            "Speed: 4.6ms preprocess, 553.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_102.jpg: 640x640 (no detections), 747.7ms\n",
            "Speed: 4.7ms preprocess, 747.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1020.jpg: 640x480 1 Baseball Field, 2 Boeing777s, 665.1ms\n",
            "Speed: 5.0ms preprocess, 665.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1021.jpg: 480x640 (no detections), 656.9ms\n",
            "Speed: 5.2ms preprocess, 656.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1022.jpg: 640x480 (no detections), 651.6ms\n",
            "Speed: 5.1ms preprocess, 651.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1023.jpg: 480x640 1 A350, 1 Baseball Field, 430.6ms\n",
            "Speed: 5.3ms preprocess, 430.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1024.jpg: 640x640 (no detections), 538.5ms\n",
            "Speed: 4.6ms preprocess, 538.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1025.jpg: 480x640 1 A350, 428.1ms\n",
            "Speed: 3.3ms preprocess, 428.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1026.jpg: 640x480 1 Baseball Field, 415.3ms\n",
            "Speed: 3.4ms preprocess, 415.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1027.jpg: 640x480 (no detections), 420.6ms\n",
            "Speed: 4.9ms preprocess, 420.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1028.jpg: 640x640 5 Baseball Fields, 2 Boeing777s, 553.5ms\n",
            "Speed: 4.7ms preprocess, 553.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1029.jpg: 480x640 (no detections), 412.3ms\n",
            "Speed: 3.6ms preprocess, 412.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_103.jpg: 640x480 1 A350, 1 Baseball Field, 2 Boeing747s, 428.0ms\n",
            "Speed: 5.3ms preprocess, 428.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1030.jpg: 640x640 (no detections), 545.6ms\n",
            "Speed: 4.5ms preprocess, 545.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1031.jpg: 640x640 (no detections), 566.1ms\n",
            "Speed: 4.8ms preprocess, 566.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1032.jpg: 640x640 1 A350, 562.6ms\n",
            "Speed: 4.8ms preprocess, 562.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1033.jpg: 640x640 1 Baseball Field, 534.1ms\n",
            "Speed: 4.6ms preprocess, 534.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1034.jpg: 640x480 (no detections), 424.8ms\n",
            "Speed: 3.3ms preprocess, 424.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1035.jpg: 640x480 (no detections), 404.7ms\n",
            "Speed: 3.4ms preprocess, 404.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1036.jpg: 480x640 1 A321, 408.4ms\n",
            "Speed: 4.3ms preprocess, 408.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1037.jpg: 640x480 (no detections), 431.4ms\n",
            "Speed: 3.8ms preprocess, 431.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1038.jpg: 640x640 1 Boeing777, 538.1ms\n",
            "Speed: 4.7ms preprocess, 538.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1039.jpg: 640x480 1 Boeing747, 432.6ms\n",
            "Speed: 4.1ms preprocess, 432.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_104.jpg: 640x480 (no detections), 410.0ms\n",
            "Speed: 3.5ms preprocess, 410.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1040.jpg: 480x640 (no detections), 416.7ms\n",
            "Speed: 3.4ms preprocess, 416.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1041.jpg: 640x480 (no detections), 495.1ms\n",
            "Speed: 3.9ms preprocess, 495.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1042.jpg: 480x640 1 ARJ21, 1 Bus, 652.4ms\n",
            "Speed: 4.6ms preprocess, 652.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1043.jpg: 640x640 (no detections), 839.5ms\n",
            "Speed: 8.2ms preprocess, 839.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1044.jpg: 480x640 (no detections), 658.1ms\n",
            "Speed: 10.1ms preprocess, 658.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1045.jpg: 480x640 (no detections), 471.9ms\n",
            "Speed: 4.8ms preprocess, 471.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1046.jpg: 640x480 1 Baseball Field, 414.5ms\n",
            "Speed: 3.4ms preprocess, 414.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1047.jpg: 640x640 1 Baseball Field, 1 Boeing777, 557.5ms\n",
            "Speed: 4.6ms preprocess, 557.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1048.jpg: 640x640 (no detections), 542.5ms\n",
            "Speed: 5.4ms preprocess, 542.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1049.jpg: 640x640 (no detections), 554.8ms\n",
            "Speed: 4.6ms preprocess, 554.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_105.jpg: 480x640 (no detections), 409.9ms\n",
            "Speed: 3.4ms preprocess, 409.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1050.jpg: 640x640 (no detections), 558.7ms\n",
            "Speed: 6.0ms preprocess, 558.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1051.jpg: 480x640 (no detections), 409.0ms\n",
            "Speed: 3.3ms preprocess, 409.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1052.jpg: 480x640 (no detections), 408.7ms\n",
            "Speed: 3.3ms preprocess, 408.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1053.jpg: 640x480 2 Baseball Fields, 426.0ms\n",
            "Speed: 3.8ms preprocess, 426.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1054.jpg: 640x480 (no detections), 418.1ms\n",
            "Speed: 4.6ms preprocess, 418.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1055.jpg: 640x480 (no detections), 424.9ms\n",
            "Speed: 3.3ms preprocess, 424.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1056.jpg: 480x640 (no detections), 410.6ms\n",
            "Speed: 3.5ms preprocess, 410.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1057.jpg: 640x640 (no detections), 547.1ms\n",
            "Speed: 4.9ms preprocess, 547.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1058.jpg: 640x640 (no detections), 539.7ms\n",
            "Speed: 4.8ms preprocess, 539.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1059.jpg: 640x640 (no detections), 544.1ms\n",
            "Speed: 5.4ms preprocess, 544.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_106.jpg: 640x480 (no detections), 419.0ms\n",
            "Speed: 3.4ms preprocess, 419.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1060.jpg: 640x640 (no detections), 541.5ms\n",
            "Speed: 5.4ms preprocess, 541.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1061.jpg: 640x640 (no detections), 534.3ms\n",
            "Speed: 4.5ms preprocess, 534.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1062.jpg: 480x640 2 A350s, 421.1ms\n",
            "Speed: 3.3ms preprocess, 421.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1063.jpg: 480x640 (no detections), 503.2ms\n",
            "Speed: 3.3ms preprocess, 503.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1064.jpg: 640x480 1 A350, 661.3ms\n",
            "Speed: 5.0ms preprocess, 661.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1065.jpg: 640x640 (no detections), 857.9ms\n",
            "Speed: 6.7ms preprocess, 857.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1066.jpg: 640x640 (no detections), 819.2ms\n",
            "Speed: 7.6ms preprocess, 819.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1067.jpg: 640x640 (no detections), 560.4ms\n",
            "Speed: 4.4ms preprocess, 560.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1068.jpg: 480x640 1 Baseball Field, 404.7ms\n",
            "Speed: 3.5ms preprocess, 404.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1069.jpg: 640x480 1 A350, 429.0ms\n",
            "Speed: 3.5ms preprocess, 429.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_107.jpg: 480x640 (no detections), 407.3ms\n",
            "Speed: 3.7ms preprocess, 407.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1070.jpg: 640x480 (no detections), 428.3ms\n",
            "Speed: 3.3ms preprocess, 428.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1071.jpg: 480x640 (no detections), 410.7ms\n",
            "Speed: 3.3ms preprocess, 410.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1072.jpg: 640x480 (no detections), 416.4ms\n",
            "Speed: 3.4ms preprocess, 416.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1073.jpg: 640x480 (no detections), 445.7ms\n",
            "Speed: 5.3ms preprocess, 445.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1074.jpg: 640x640 1 A220, 1 Baseball Field, 533.4ms\n",
            "Speed: 4.6ms preprocess, 533.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1075.jpg: 640x640 (no detections), 545.6ms\n",
            "Speed: 5.8ms preprocess, 545.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1076.jpg: 640x640 (no detections), 578.6ms\n",
            "Speed: 4.9ms preprocess, 578.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1077.jpg: 640x480 (no detections), 419.1ms\n",
            "Speed: 3.8ms preprocess, 419.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1078.jpg: 480x640 (no detections), 411.2ms\n",
            "Speed: 3.5ms preprocess, 411.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1079.jpg: 640x640 1 Baseball Field, 566.5ms\n",
            "Speed: 4.6ms preprocess, 566.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_108.jpg: 480x640 (no detections), 408.4ms\n",
            "Speed: 3.4ms preprocess, 408.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1080.jpg: 480x640 (no detections), 425.8ms\n",
            "Speed: 3.3ms preprocess, 425.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1081.jpg: 640x640 (no detections), 540.0ms\n",
            "Speed: 4.9ms preprocess, 540.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1082.jpg: 640x640 (no detections), 557.2ms\n",
            "Speed: 4.7ms preprocess, 557.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1083.jpg: 480x640 (no detections), 410.4ms\n",
            "Speed: 3.3ms preprocess, 410.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1084.jpg: 640x480 (no detections), 428.8ms\n",
            "Speed: 3.5ms preprocess, 428.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1085.jpg: 640x480 (no detections), 504.8ms\n",
            "Speed: 4.3ms preprocess, 504.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1086.jpg: 640x640 (no detections), 876.0ms\n",
            "Speed: 7.2ms preprocess, 876.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/fair1m/images/val/v_1087.jpg: 640x640 (no detections), 946.4ms\n",
            "Speed: 6.7ms preprocess, 946.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    }
  ]
}